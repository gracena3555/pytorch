{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a36db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 2 pytorch model\\n깊은 신경망을 이용한 classification 문제 해결\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 2 pytorch model\n",
    "깊은 신경망을 이용한 classification 문제 해결\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49042fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 첫번째 레이어의 형태 (Convolutional Layer)\\n합성곱(in_channel=1, out_channel=32, kernel_size=3, stride=1, padding=1) + 활성화 함수(ReLU)\\nMaxPooling(kernel_size=2, stride=2)\\n\\n# 두번째 레이어의 형태 (Convolutional Layer)\\n합성곱(in_channel=1, out_channel=64, kernel_size=3, stride=1, padding=1) + 활성화 함수(ReLU)\\nMaxPooling(kernel_size=2, stride=2)\\n\\n# 세번째 레이어의 형태 (Convolutional Layer)\\n합성곱(in_channel=1, out_channel=128, kernel_size=3, stride=1, padding=1) + 활성화 함수(ReLU)\\nMaxPooling(kernel_size=2, stride=2, padding=1)\\n\\n# 네번째 레이어 : 전결합층(FC layer)\\n특성맵을 펼치는 역할\\nFC(Fully connected) layer + 활성화 함수(ReLU)\\n\\n# 다섯번째 레이어: 전결합층(FC layer)\\nFC(Fully connected) layer + 활성화 함수(Softmax)\\n(마지막 노드는 10개) -> 0~9까지의 정답을 가져야 하기 때문에 노드를 10개를 설정\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 첫번째 레이어의 형태 (Convolutional Layer)\n",
    "합성곱(in_channel=1, out_channel=32, kernel_size=3, stride=1, padding=1) + 활성화 함수(ReLU)\n",
    "MaxPooling(kernel_size=2, stride=2)\n",
    "\n",
    "# 두번째 레이어의 형태 (Convolutional Layer)\n",
    "합성곱(in_channel=32, out_channel=64, kernel_size=3, stride=1, padding=1) + 활성화 함수(ReLU)\n",
    "MaxPooling(kernel_size=2, stride=2)\n",
    "\n",
    "# 세번째 레이어의 형태 (Convolutional Layer)\n",
    "합성곱(in_channel=64, out_channel=128, kernel_size=3, stride=1, padding=1) + 활성화 함수(ReLU)\n",
    "MaxPooling(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "# 네번째 레이어 : 전결합층(FC layer)\n",
    "특성맵을 펼치는 역할\n",
    "FC(Fully connected) layer + 활성화 함수(ReLU)\n",
    "\n",
    "# 다섯번째 레이어: 전결합층(FC layer)\n",
    "FC(Fully connected) layer + 활성화 함수(Softmax)\n",
    "(마지막 노드는 10개) -> 0~9까지의 정답을 가져야 하기 때문에 노드를 10개를 설정\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93211b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습 진행에 필요한 라이브러리 import\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c92212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용을 위한 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드를 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# 위의 고정 랜덤 시드는 GPU가 사용 가능 할 경우에 고정됨\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded6256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 파라미터 설정하기\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d02a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision 데이터로드의 데이터셋을 정의\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9301aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 크기를 지정하는 과정\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)\n",
    "\n",
    "# 60,000개의 데이터가 batch_size 100의 크기로 진행되기 때문에 total batch는 600이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385d7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스를 이용하여 모델을 설계하기\n",
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        \n",
    "        # 첫번째 레이어\n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # 두번째 레이어\n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # 세번째 레이어\n",
    "        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 128,kernel_size=3, stride=1, padding=1),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
    "        # 네번째 레이어\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(self.fc1,\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.Dropout(p=1 - self.keep_prob)) # 드롭아웃 : 과적합 방지\n",
    "        \n",
    "        # 다섯번째 레이어\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    # 순전파 전달을 위한 함수 forward 선언\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1) # 텐서를 펼치는 역할 : Flatten\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91691f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델을 정의\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62dbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수와 옵티마이저 선언\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417bc7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "# 총 배치의 수 확인하기(파라미터 조정하기)\n",
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "# 사용자가 지정한 배치의 수에 따라 총 배치의 수가 달라짐을 볼 수 있음\n",
    "# 배치 횟수 변경, 에폭 횟수 변경, 옵티마이저 변경, 손실함수 변경(비용함수) 등을\n",
    "# 여러 방법으로 변경해보며 어떤 환경이 최적이었는지 판단하는 과정을 거쳐, 사용에 있어서 최적의 모델을 만들어 냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a929fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.0520880297\n",
      "[Epoch:    2] cost = 0.0373753347\n",
      "[Epoch:    3] cost = 0.0291581377\n",
      "[Epoch:    4] cost = 0.024159167\n",
      "[Epoch:    5] cost = 0.0190590918\n",
      "[Epoch:    6] cost = 0.0166242737\n",
      "[Epoch:    7] cost = 0.0149003444\n",
      "[Epoch:    8] cost = 0.0119782947\n",
      "[Epoch:    9] cost = 0.0119551318\n",
      "[Epoch:   10] cost = 0.0109440945\n",
      "[Epoch:   11] cost = 0.00998318754\n",
      "[Epoch:   12] cost = 0.00926795416\n",
      "[Epoch:   13] cost = 0.00769248838\n",
      "[Epoch:   14] cost = 0.00677237147\n",
      "[Epoch:   15] cost = 0.00631714566\n",
      "[Epoch:   16] cost = 0.00807369594\n",
      "[Epoch:   17] cost = 0.00612992607\n",
      "[Epoch:   18] cost = 0.00635896716\n",
      "[Epoch:   19] cost = 0.00416793255\n",
      "[Epoch:   20] cost = 0.00606178399\n",
      "[Epoch:   21] cost = 0.00526609458\n",
      "[Epoch:   22] cost = 0.0049467748\n",
      "[Epoch:   23] cost = 0.00411565835\n",
      "[Epoch:   24] cost = 0.00376606663\n",
      "[Epoch:   25] cost = 0.00679196091\n",
      "[Epoch:   26] cost = 0.00490249228\n",
      "[Epoch:   27] cost = 0.00502852257\n",
      "[Epoch:   28] cost = 0.00312327174\n",
      "[Epoch:   29] cost = 0.0032575326\n",
      "[Epoch:   30] cost = 0.00389588973\n",
      "[Epoch:   31] cost = 0.0029070538\n",
      "[Epoch:   32] cost = 0.00447019981\n",
      "[Epoch:   33] cost = 0.00571579766\n",
      "[Epoch:   34] cost = 0.00413753139\n",
      "[Epoch:   35] cost = 0.00393386371\n",
      "[Epoch:   36] cost = 0.00365177519\n",
      "[Epoch:   37] cost = 0.00486965617\n",
      "[Epoch:   38] cost = 0.00136253156\n",
      "[Epoch:   39] cost = 0.00477776257\n",
      "[Epoch:   40] cost = 0.00260766339\n",
      "[Epoch:   41] cost = 0.00551352743\n",
      "[Epoch:   42] cost = 0.0022518395\n",
      "[Epoch:   43] cost = 0.00411814684\n",
      "[Epoch:   44] cost = 0.00269272621\n",
      "[Epoch:   45] cost = 0.00432202918\n",
      "[Epoch:   46] cost = 0.00372582464\n",
      "[Epoch:   47] cost = 0.00317003368\n",
      "[Epoch:   48] cost = 0.00399216916\n",
      "[Epoch:   49] cost = 0.004300653\n",
      "[Epoch:   50] cost = 0.00305991643\n",
      "[Epoch:   51] cost = 0.00235090405\n",
      "[Epoch:   52] cost = 0.00393709261\n",
      "[Epoch:   53] cost = 0.00126999931\n",
      "[Epoch:   54] cost = 0.00363870594\n",
      "[Epoch:   55] cost = 0.00396282319\n",
      "[Epoch:   56] cost = 0.00210540323\n",
      "[Epoch:   57] cost = 0.00302311382\n",
      "[Epoch:   58] cost = 0.00409288146\n",
      "[Epoch:   59] cost = 0.00519290101\n",
      "[Epoch:   60] cost = 0.00315799704\n",
      "[Epoch:   61] cost = 0.00276409835\n",
      "[Epoch:   62] cost = 0.00294707506\n",
      "[Epoch:   63] cost = 0.00177245692\n",
      "[Epoch:   64] cost = 0.00357073103\n",
      "[Epoch:   65] cost = 0.0030512088\n",
      "[Epoch:   66] cost = 0.00394727942\n",
      "[Epoch:   67] cost = 0.00469969772\n",
      "[Epoch:   68] cost = 0.00183083874\n",
      "[Epoch:   69] cost = 0.00450111832\n",
      "[Epoch:   70] cost = 0.00324067031\n",
      "[Epoch:   71] cost = 0.00220359815\n",
      "[Epoch:   72] cost = 0.00217630109\n",
      "[Epoch:   73] cost = 0.00650471821\n",
      "[Epoch:   74] cost = 0.00216101925\n",
      "[Epoch:   75] cost = 0.00137960305\n",
      "[Epoch:   76] cost = 0.00173763302\n",
      "[Epoch:   77] cost = 0.00474243471\n",
      "[Epoch:   78] cost = 0.00377026969\n",
      "[Epoch:   79] cost = 0.00323219551\n",
      "[Epoch:   80] cost = 0.00239971466\n",
      "[Epoch:   81] cost = 0.00356155168\n",
      "[Epoch:   82] cost = 0.00463069091\n",
      "[Epoch:   83] cost = 0.00430594012\n",
      "[Epoch:   84] cost = 0.00277066813\n",
      "[Epoch:   85] cost = 0.00284738443\n",
      "[Epoch:   86] cost = 0.00307583343\n",
      "[Epoch:   87] cost = 0.00420576986\n",
      "[Epoch:   88] cost = 0.0023198491\n",
      "[Epoch:   89] cost = 0.00228278013\n",
      "[Epoch:   90] cost = 0.0037177864\n",
      "[Epoch:   91] cost = 0.00242413371\n",
      "[Epoch:   92] cost = 0.0028149751\n",
      "[Epoch:   93] cost = 0.00573788676\n",
      "[Epoch:   94] cost = 0.00268671708\n",
      "[Epoch:   95] cost = 0.00127835386\n",
      "[Epoch:   96] cost = 0.00203896314\n",
      "[Epoch:   97] cost = 0.00228621112\n",
      "[Epoch:   98] cost = 0.00454170723\n",
      "[Epoch:   99] cost = 0.00608908711\n",
      "[Epoch:  100] cost = 0.00151608\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        \n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ccbf414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9560999870300293\n"
     ]
    }
   ],
   "source": [
    "# 모델 테스트\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688c776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
